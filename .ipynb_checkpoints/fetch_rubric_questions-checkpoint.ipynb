{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyring        # for loading api token\n",
    "import urllib.request # for encoding URL parameters\n",
    "import pandas as pd   # for handling data frames\n",
    "import json           # for handling json\n",
    "import os             # for outputting the absolute path of the file containing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication\n",
    "\n",
    "Please read the Authentication section of the [README](README.ipynb) to set up your acess token for the following code.  <span style=\"color:red\"> WARNING: the below code will load the access token you saved from the README.ipynb</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = keyring.get_password(\"system\", \"canvas_token\");\n",
    "print(\"Loaded token with %d characters.\" % (len(token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "The following configuration does not frequently change. Input your course ID found in the url of your canvas course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_id = int(input(\"Enter your course id here: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next one can change based on your rubric.  This can be found from the data returned from the assignments notebook or by looking at the outcomes section of canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_id = int(input(\"Enter your rubric id here: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'base_url': 'https://usfca.instructure.com',\n",
    "        'course_id': course_id,\n",
    "        'rubric': rubric_id\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Setup\n",
    "\n",
    "The following sets up the REST API request to get a rubric:\n",
    "\n",
    "<https://canvas.instructure.com/doc/api/rubrics.html#method.rubrics_api.show>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_format = '{base_url}/api/v1/courses/{course_id}/rubrics/{rubric}'\n",
    "api_url = api_format.format(**config)\n",
    "print(\"URL:\", api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'per_page': 200,\n",
    "    'include[]': 'assessments',\n",
    "    'style':'full'\n",
    "}\n",
    "\n",
    "encoded = urllib.parse.urlencode(params)\n",
    "print(\"Params:\", encoded) # do not output api key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_call = '{}?access_token={}&{}'.format(api_url, token, encoded)\n",
    "print(\"REST call is %d characters.\" % (len(rest_call)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data\n",
    "\n",
    "Fetch the JSON data from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to the format of this json object, some preprocessing using the json library needs to be done then converted to a dataframe\n",
    "with urllib.request.urlopen(rest_call) as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "data = pd.DataFrame.from_dict(data, orient='index')\n",
    "print('Loaded {} rows and {} columns.'.format(*data.shape))\n",
    "# The column should be the rubric \n",
    "# the rows are the information about the rubric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output columns (should be one due to requesting one rubric)\n",
    "print('Columns:', list(data.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # look at the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to obtain question information if there is one in the assignment.  These questions correspond to the questions on a rubric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    questions = data.loc['criteria']\n",
    "except KeyError:\n",
    "    print(\"There is no question information here please input a new assignment or check that your access token is accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = pd.DataFrame.from_dict(questions) # we only need the criteria from the data gathered from the api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Criteria Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe out of the criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded = converted.explode(\"criteria\") # converted is a single row containing a list of all questions of a rubric\n",
    "expanded.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded.head() # look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded.loc[0, \"criteria\"] # look at a single question of a rubric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling\n",
    "\n",
    "Some of the columns could use some wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangled = expanded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dictionary that corresponds to the question into a row of a dataframe for all rows\n",
    "criteria = wrangled.criteria.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many similar names with each endpoint of the data these two columns in particular could be more clear\n",
    "criteria.rename(columns={\"id\":\"criterion_id\", \"points\":\"points_possible\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = criteria.explode(\"ratings\") # gets the ratings (this is the information for ratings within the question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.ratings.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.columns = [\"ratings_\" + item for item in ratings.columns.tolist()] # some columns may have the same name so change them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.concat([criteria, ratings], axis=1) # combine both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head() # note that here you may have duplicate rows due to the fact that each question has a choice of multiple ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop(columns=[\"ratings\"], inplace=True) # since we combined the rating information, we can safely drop the column without losing information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this if you already saved a set of questions to a file and want to add another set of questions to it from another assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = pd.read_csv('questions.csv')\n",
    "# final = pd.concat([final, questions], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Results\n",
    "\n",
    "Output the results to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'questions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(path, header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('questions.csv') # the absolute path of the result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
